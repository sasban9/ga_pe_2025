Sitting astronaut
Learn Prompting

Prompt Engineering Guide
ğŸ˜ƒ Basics
ğŸŸ¢ Basics Guide Overview
ğŸŸ¢ What is Generative AI?
ğŸŸ¢ ChatGPT Basics
<!-- ğŸŸ¢ Testing Prompts with Interactive Learn Prompting Embeds -->
ğŸŸ¢ Introduction to Prompt Engineering
ğŸŸ¢ Basic Prompt Structure and Key Parts
ğŸŸ¢ Technique #1: Instructions in Prompts
ğŸŸ¢ Technique #2: Roles in Prompts
ğŸŸ¢ Technique #3: Examples in Prompts: From Zero-Shot to Few-Shot
ğŸŸ¢ Combining Prompting Techniques
ğŸŸ¢ Tips for Writing Better Prompts
ğŸŸ¢ Prompt Priming: Setting Context for AI
ğŸŸ¢ Differences Between Chatbots and LLMs
ğŸŸ¢ LLM Limitations: When Models and Chatbots Make Mistakes
ğŸŸ¢ What Can Generative AI Create Beyond Text?
ğŸŸ¢ How to Solve Problems Using Generative AI: A Simple Method
ğŸŸ¢ Next Steps: Where to Go From Here
ğŸ’¼ Applications
ğŸŸ¢ Introduction
ğŸŸ¢ Text Summarization
ğŸŸ¢ Table Generation
ğŸŸ¢ Multiple Choice Questions
ğŸŸ¢ Short-Form Content
ğŸŸ¢ Writing in Different Styles
ğŸŸ¢ Finding Emojis
ğŸŸ¢ Writing Emails
ğŸŸ¢ Blog Writing
ğŸŸ¢ Legal Documents
ğŸŸ¢ Study Buddy
ğŸŸ¦ Digital Marketing
ğŸŸ¦ Coding Assistance
ğŸŸ¦ Knowledge Base Chatbot
ğŸŸ¦ How to Build a Chatbot Using LLMs
ğŸŸ¦ Zapier for Emails
ğŸ§™â€â™‚ï¸ Intermediate
ğŸŸ¢ Introduction
ğŸŸ¢ Chain-of-Thought Prompting
ğŸŸ¢ Zero-Shot Chain-of-Thought
ğŸŸ¦ Self-Consistency
ğŸŸ¦ Generated Knowledge
ğŸŸ¦ Least-to-Most Prompting
ğŸŸ¦ Dealing With Long Form Content
ğŸŸ¦ Revisiting Roles
ğŸŸ¦ More About Prompt Elements
ğŸŸ¦ Basic LLM Settings
ğŸŸ¦ OpenAI Playground
ğŸ§  Advanced
ğŸŸ¢ Introduction
Zero-Shot
ğŸŸ¢ Introduction
ğŸŸ¢ Emotion Prompting
ğŸŸ¢ Role Prompting
ğŸŸ¢ Re-reading (RE2)
ğŸŸ¢ Rephrase and Respond (RaR)
ğŸŸ¦ SimToM
â—† System 2 Attention (S2A)
Few-Shot
ğŸŸ¢ Introduction
ğŸŸ¢ Self-Ask
ğŸŸ¢ Self Generated In-Context Learning (SG-ICL)
ğŸŸ¢ Chain-of-Dictionary (CoD)
ğŸŸ¢ Cue-CoT
ğŸŸ¦ Chain of Knowledge (CoK)
â—† K-Nearest Neighbor (KNN)
â—†â—† Vote-K
â—†â—† Prompt Mining
Thought Generation
ğŸŸ¢ Introduction
ğŸŸ¢ Chain of Draft (CoD)
ğŸŸ¦ Contrastive Chain-of-Thought
ğŸŸ¦ Automatic Chain of Thought (Auto-CoT)
ğŸŸ¦ Tabular Chain-of-Thought (Tab-CoT)
ğŸŸ¦ Memory-of-Thought (MoT)
ğŸŸ¦ Active Prompting
ğŸŸ¦ Analogical Prompting
ğŸŸ¦ Complexity-Based Prompting
ğŸŸ¦ Step-Back Prompting
ğŸŸ¦ Thread of Thought (ThoT)
Ensembling
ğŸŸ¢ Introduction
ğŸŸ¢ Universal Self-Consistency
ğŸŸ¦ Mixture of Reasoning Experts (MoRE)
ğŸŸ¦ Max Mutual Information (MMI) Method
ğŸŸ¦ Prompt Paraphrasing
ğŸŸ¦ DiVeRSe (Diverse Verifier on Reasoning Step)
ğŸŸ¦ Universal Self-Adaptive Prompting (USP)
ğŸŸ¦ Consistency-based Self-adaptive Prompting (COSP)
ğŸŸ¦ Multi-Chain Reasoning (MCR)
Self-Criticism
ğŸŸ¢ Introduction
ğŸŸ¢ Self-Calibration
ğŸŸ¢ Chain of Density (CoD)
ğŸŸ¢ Chain-of-Verification (CoVe)
ğŸŸ¦ Self-Refine
ğŸŸ¦ Cumulative Reasoning
ğŸŸ¦ Reversing Chain-of-Thought (RCoT)
â—† Self-Verification
Decomposition
ğŸŸ¢ Introduction
ğŸŸ¢ Chain-of-Logic
ğŸŸ¦ Decomposed Prompting
ğŸŸ¦ Plan-and-Solve Prompting
ğŸŸ¦ Program of Thoughts
ğŸŸ¦ Tree of Thoughts
ğŸŸ¦ Chain of Code (CoC)
ğŸŸ¦ Duty-Distinct Chain-of-Thought (DDCoT)
â—† Faithful Chain-of-Thought
â—† Recursion of Thought
â—† Skeleton-of-Thought
Special Topics
âš–ï¸ Reliability
ğŸŸ¢ Introduction
ğŸŸ¢ Prompt Debiasing
ğŸŸ¦ Prompt Ensembling
ğŸŸ¦ LLM Self-Evaluation
ğŸŸ¦ Calibrating LLMs
ğŸŸ¦ Math
ğŸ”“ Prompt Hacking
ğŸŸ¢ Introduction
ğŸŸ¢ Prompt Injection
ğŸŸ¢ Prompt Leaking
ğŸŸ¢ Jailbreaking
ğŸŸ¢ Defensive Measures
ğŸŸ¢ Introduction
ğŸŸ¢ Filtering
ğŸŸ¢ Instruction Defense
ğŸŸ¢ Post-Prompting
ğŸŸ¢ Random Sequence Enclosure
ğŸŸ¢ Sandwich Defense
ğŸŸ¢ XML Tagging
ğŸŸ¢ Separate LLM Evaluation
ğŸŸ¢ Other Approaches
ğŸŸ¢ Offensive Measures
ğŸŸ¢ Introduction
ğŸŸ¢ Simple Instruction Attack
ğŸŸ¢ Context Ignoring Attack
ğŸŸ¢ Compound Instruction Attack
ğŸŸ¢ Special Case Attack
ğŸŸ¢ Few-Shot Attack
ğŸŸ¢ Refusal Suppression
ğŸŸ¢ Context Switching Attack
ğŸŸ¢ Obfuscation/Token Smuggling
ğŸŸ¢ Task Deflection Attack
ğŸŸ¢ Payload Splitting
ğŸŸ¢ Defined Dictionary Attack
ğŸŸ¢ Indirect Injection
ğŸŸ¢ Recursive Injection
ğŸŸ¢ Code Injection
ğŸŸ¢ Virtualization
ğŸŸ¢ Pretending
ğŸŸ¢ Alignment Hacking
ğŸŸ¢ Authorized User
ğŸŸ¢ DAN (Do Anything Now)
ğŸŸ¢ Bad Chain
ğŸ–¼ï¸ Image Prompting
ğŸŸ¢ Introduction
ğŸŸ¢ Style Modifiers
ğŸŸ¢ Quality Boosters
ğŸŸ¢ Repetition
ğŸŸ¢ Weighted Terms
ğŸŸ¢ Fix Deformed Generations
ğŸŸ¢ Shot type
ğŸŸ¢ Midjourney
ğŸŸ¢ Resources
ğŸŒ± New Techniques
ğŸŸ¢ Introduction
ğŸŸ¢ Aligned Chain-of-Thought (AlignedCoT)
ğŸŸ¦ Self-Harmonized Chain-of-Thought (ECHO)
ğŸŸ¦ Logic-of-Thought (LoT)
ğŸŸ¦ Narrative-of-Thought (NoT)
ğŸŸ¦ Code Prompting
â—† End-to-End DAG-Path (EEDP) Prompting
â—† Instance-adaptive Zero-Shot Chain-of-Thought Prompting (IAP)
ğŸ”§ Models
ğŸŸ¢ Introduction
ğŸŸ¢ OpenAI o1
ğŸŸ¢ FLUID
ğŸŸ¢ Stable Diffusion 3.5
ğŸŸ¢ DALL-E 3
ğŸŸ¢ Anthropic Claude
ğŸŸ¦ Apple Intelligence Models
ğŸŸ¢ Google Gemini 1.5
ğŸŸ¢ Gemini 1.5 Flash
ğŸŸ¢ Gemini 1.5 Pro
ğŸŸ¢ Gemma
ğŸŸ¢ Janus
ğŸ—‚ï¸ RAG
ğŸŸ¢ Introduction
ğŸŸ¦ Retrieval-Augmented Generation (RAG)
ğŸŸ¦ Auto-RAG
ğŸŸ¦ Self-RAG
ğŸŸ¦ FLARE / Active RAG
ğŸŸ¦ R^2AG
ğŸŸ¦ GraphRAG
ğŸŸ¦ InFO-RAG
ğŸŸ¦ HybridRAG
ğŸŸ¦ Corrective RAG
ğŸŸ¦ Speculative RAG
ğŸŸ¦ Reliability-Aware RAG (RA-RAG)
ğŸŸ¦ Multi-Fusion Retrieval Augmented Generation (MoRAG)
ğŸ¤– Agents
ğŸŸ¢ Introduction
ğŸŸ¦ LLMs Using Tools
ğŸŸ¦ LLMs that Reason and Act
ğŸŸ¦ Code as Reasoning
ğŸ’ª Prompt Tuning
ğŸŸ¢ Introduction
ğŸŸ¦ Prompt Tuning with Soft Prompts
ğŸŸ¦ Interpretable Soft Prompts
ğŸŸ¦ Prefix-Tuning
ğŸŸ¦ Prompt-Tuning with Perturbation-Based Regularizer
ğŸŸ¦ Low-Rank Prompt Tuning (LoPT)
ğŸŸ¦ Dynamic Prompting
ğŸŸ¦ Gradient-Free Prompt Tuning
ğŸŸ¦ Multitask Prompt Tuning
ğŸ” Language Model Inversion
ğŸŸ¢ Introduction
ğŸŸ¢ logit2prompt
ğŸŸ¢ output2prompt
ğŸŸ¢ Reverse Prompt Engineering (RPE)
ğŸ”¨ Tooling
ğŸŸ¢ Introduction
Prompt Engineering Tools
Prompt Engineering IDEs
ğŸŸ¢ Introduction
GPT-3 Playground
Dust
Soaked
Everyprompt
Prompt IDE
PromptTools
PromptSource
PromptChainer
Prompts.ai
Snorkel ğŸš§
Human Loop
Spellbook ğŸš§
Kolla Prompt ğŸš§
Lang Chain
OpenPrompt
OpenAI DALLE IDE
Dream Studio
Patience
Promptmetheus
PromptSandbox.io
The Forge AI
AnySolve
Conclusion
ğŸ² Miscellaneous
ğŸŸ¢ Introduction
ğŸŸ¢ Detection Trickery
ğŸŸ¢ Music Generation
ğŸŸ¢ Detecting AI Generated Text
Resources
ğŸ“š Bibliography
ğŸ“¦ Prompted Products
ğŸ›¸ Additional Resources
ğŸ”¥ Hot Topics
âœ¨ Credits
language symbolEnglish
Dark Mode Icon